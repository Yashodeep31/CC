 Implementation of machine learning application using Google Colab.

import numpy as np
import pandas as pd
import io
import matplotlib.pyplot as plt
plt.rcParams['figure.figsize'] = (20.0, 10.0)

from google.colab import files
data = files.upload()

import io
data = pd.read_csv(io.BytesIO(uploaded['headbrain.csv']))
#print(data)
data.head()

# Collecting X and Y
X = data['Head Size(cm^3)'].values
Y = data['Brain Weight(grams)'].values

# Calculating coefficient
# Mean X and Y
mean_x = np.mean(X)
mean_y = np.mean(Y)
print(mean_x)
print(mean_y)

# Total number of values
n = len(X)
print(n)

# Using the formula to calculate b1 and b0
numer = 0
denom = 0
for i in range(n):
  numer += (X[i] - mean_x) * (Y[i] - mean_y)
  denom += (X[i] - mean_x) ** 2
b1 = numer / denom #slope
b0 = mean_y - (b1 * mean_x) #intercept

print(b1, b0)

plt.scatter(X, Y, c='#ef5423', label='Scatter Plot')
plt.xlabel('Head Size in cm3')
plt.ylabel('Brain Weight in grams')
plt.legend()
plt.show()

max_x = np.max(X)+100
min_x = np.min(X)-100

# Calculating line values x and y
x = np.linspace(min_x,max_x,1000)
y = b0 + b1 * x

# Plotting Values and Regression Line
plt.scatter(X, Y, c='#ef5423', label='Scatter Plot')

# Ploting Line
plt.plot(x, y, color='#58b970', label='Regression Line')

# Calculating Root Mean Squares Error
rmse = 0
for i in range(n):
  y_pred = b0 + b1 * X[i]
  rmse += (Y[i] - y_pred) ** 2
rmse = np.sqrt(rmse/n)
print(rmse)

# Calculating R2 Score
ss_tot = 0
ss_res = 0
for i in range(n):
  y_pred = b0 + b1 * X[i]
  ss_tot += (Y[i] - mean_y) ** 2
  ss_res += (Y[i] - y_pred) ** 2
r2 = 1 - (ss_res/ss_tot)
print(r2)